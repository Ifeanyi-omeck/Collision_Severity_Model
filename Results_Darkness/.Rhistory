{
type <- match.arg(type)
res <- as.data.frame(object$y)-predict(object,type="response.full")
switch(type, response = {
return(res)
})
}
#expanded object-oriented function for vcov
vcov<-function (object, model = c("full", "cutpoints","inflation", "ordered"), ...)
{
model <- match.arg(model)
rval <- object$vcov
if(model == "full"){
return(rval)
}
else{
if(model=="cutpoints"){
cf <- object$coefficients[[model]]
wi <- seq(along = object$coefficients$cutpoints)
rval <- if (model == "cutpoints")
rval[wi, wi]
colnames(rval) <- rownames(rval) <- names(cf)
}
if(model=="inflation"){
cf <- object$coefficients[[model]]
wi <- seq(along = object$coefficients$inflation)
rval <- if (model == "inflation")
rval[wi, wi]
colnames(rval) <- rownames(rval) <- names(cf)
}
if(model=="ordered"){
cf <- object$coefficients[[model]]
wi <- seq(along = object$coefficients$ordered)
rval <- if (model == "ordered")
rval[wi, wi]
colnames(rval) <- rownames(rval) <- names(cf)
}
}
return(rval)
}
#Testing the 2nd model of the data
my_ziop_model <- iop(Y ~ X | Z, data = data, type = c("ziop"))
#Importing test data from the internet to test out our Model
url <- "https://github.com/hknd23/idcempy/raw/main/data/tobacco_cons.csv"
data <- read.csv(url)
data <- data[1:20, ]
#Creating columns of dataset for testing
varia <- c('age', 'grade', 'gender_dum')
X <- as.matrix(data[varia])
Y <- data$cig_count
Z <- as.matrix(data$gender_dum)
#Testing the 2nd model of the data
my_ziop_model <- iop(Y ~ X | Z, data = data, type = c("ziop"))
Z <- data$gender_dum
#Testing the 2nd model of the data
my_ziop_model <- iop(Y ~ X | Z, data = data, type = c("ziop"))
data <- read.csv(url)
X <- as.matrix(data[varia])
Y <- data$cig_count
Z <- data$gender_dum
#Testing the 2nd model of the data
my_ziop_model <- iop(Y ~ X | Z, data = data, type = c("ziop"))
summary(model_ziop)
summary(my_ziop_model)
data <- data[1:20, ]
#Creating columns of dataset for testing
varia <- c('age', 'grade', 'gender_dum')
X <- as.matrix(data[varia])
Y <- data$cig_count
Z <- data$gender_dum
#Testing the 2nd model of the data
my_ziop_model <- iop(Y ~ X | Z, data = data, type = c("ziop"))
data <- data[1:100, ]
#Creating columns of dataset for testing
varia <- c('age', 'grade', 'gender_dum')
X <- as.matrix(data[varia])
Y <- data$cig_count
Z <- data$gender_dum
#Testing the 2nd model of the data
my_ziop_model <- iop(Y ~ X | Z, data = data, type = c("ziop"))
#Importing test data from the internet to test out our Model
url <- "https://github.com/hknd23/idcempy/raw/main/data/tobacco_cons.csv"
data <- read.csv(url)
#Creating columns of dataset for testing
varia <- c('age', 'grade', 'gender_dum')
X <- as.matrix(data[varia])
Y <- data$cig_count
Z <- data$gender_dum
#Testing the 2nd model of the data
my_ziop_model <- iop(Y ~ X | Z, data = data, type = c("ziop"))
summary(my_ziop_model)
data <- data[1:500, ]
#Creating columns of dataset for testing
varia <- c('age', 'grade', 'gender_dum')
X <- as.matrix(data[varia])
Y <- data$cig_count
Z <- data$gender_dum
#Testing the 2nd model of the data
my_ziop_model <- iop(Y ~ X | Z, data = data, type = c("ziop"))
summary(my_ziop_model)
rm(list = ls())
setwd("C:/Users/user/Documents/Personal_items/Books/Bayesian Books/Dissertation_codes/Data set for Diss")
# Load the required packages for Zero inflated Ordered Probit model and the Ordinal Model.
library(zmiop)
library(ordinal)
# Set a seed for reproducibility
seed_value <- 123
set.seed(seed_value)
# Fitting model for the first iteration of the zero inflated ordered probit model for Day light.
# Load the prepared data set for modelling.
prep_data <- read.csv('final_dataset_darkness.csv')
# Fitting the first Traditional ordered Probit model using the CLM function in the ordinal package.
Op_one_darkness <- clm(factor(recoded_severity) ~ road_type +  speed_limit + weather_conditions + road_surface_conditions +
special_conditions_at_site + carriageway_hazards + urban_or_rural_area + vehicle_type +
skidding_and_overturning + first_point_of_impact + journey_purpose_of_driver + sex_of_driver +
age_of_driver + age_of_vehicle + sex_of_casualty + age_of_casualty + car_passenger,
data = prep_data, link = 'probit')
summary(Op_one_darkness)
# Fitting the Zero inflated Ordered Probit model with significant estimates from the Ordered Probit Model
ziop_one_darkness <- iop(recoded_severity ~  road_type + speed_limit + weather_conditions + road_surface_conditions +
special_conditions_at_site + carriageway_hazards + urban_or_rural_area +
vehicle_type + skidding_and_overturning + first_point_of_impact +
journey_purpose_of_driver + sex_of_driver + age_of_driver + age_of_vehicle +
sex_of_casualty + age_of_casualty + car_passenger | road_type + speed_limit +
weather_conditions + road_surface_conditions + special_conditions_at_site +
carriageway_hazards + urban_or_rural_area + vehicle_type + skidding_and_overturning +
first_point_of_impact + journey_purpose_of_driver + sex_of_driver + age_of_driver +
age_of_vehicle +  sex_of_casualty + age_of_casualty + car_passenger,
data = prep_data, type = c('ziop'))
summary(ziop_one_darkness)
summary(ziop_one_darkness)
# Compare statistically significant variables in the OP model and ZIOP model, pick statistically significant variables
# in either model and common to both models
# fitting the model again with statistically significant variables
ziop_two_darkness <- iop(recoded_severity ~  weather_conditions + urban_or_rural_area + skidding_and_overturning +
age_of_driver + road_type + vehicle_type + journey_purpose_of_driver +
sex_of_driver + age_of_vehicle + car_passenger | weather_conditions +
urban_or_rural_area + skidding_and_overturning + age_of_driver + road_type +
vehicle_type + journey_purpose_of_driver + sex_of_driver + age_of_vehicle +
car_passenger, data = prep_data, type = c('ziop'))
summary(ziop_two_darkness)
# Fit a standard ordered probit model with the same variables for comparison
final_op_darkness <- clm(factor(recoded_severity) ~  weather_conditions + urban_or_rural_area + skidding_and_overturning +
age_of_driver + road_type + vehicle_type + journey_purpose_of_driver +
sex_of_driver + age_of_casualty + car_passenger,
data = prep_data, link = 'probit')
summary(final_op_darkness)
# Saving the results of the Zero inflated Ordered Probit to a csv file
ziop_model <- summary(ziop_two_darkness)$coefficients
ziop_model <- as.data.frame(ziop_model)
ziop_model
# Navigate to the 'Results' folder within the current working directory
setwd("Results_Darkness")
write.csv(ziop_model, 'Estimates_ZIOP_darkness.csv', row.names = FALSE)
# Saving the results of the Ordered Probit model to a csv file.
Op_final_results <-  final_op_darkness$coefficients
Op_final_results <- as.data.frame(Op_final_results)
write.csv(Op_final_results, 'Estimates_OP_daylight.csv', row.names = FALSE)
###################################################################################################################################################
# Calculate AIC BIC and Log likelihood for the Ordered Probit model and them to csv
compute_AIC_BIC_LL <- function(model, file_suffix) {
aic <- AIC(model)
print(paste("AIC:", aic))
bic <- BIC(model)
print(paste("BIC:", bic))
logLik_value <- logLik(model)
print(paste("Log-Likelihood:", logLik_value))
# Create data frames for AIC, BIC, and log-likelihood values
aic_df <- data.frame(AIC = aic)
bic_df <- data.frame(BIC = bic)
log_likelihood_df <- data.frame(LogLikelihood = logLik_value)
# Save the data frames to separate CSV files with the specified file_suffix
write.csv(aic_df, file = paste0("AIC_", file_suffix, ".csv"), row.names = FALSE)
write.csv(bic_df, file = paste0("BIC_", file_suffix, ".csv"), row.names = FALSE)
write.csv(log_likelihood_df, file = paste0("LogLikelihood_", file_suffix, ".csv"), row.names = FALSE)
}
library(MASS)
library(dplyr)
library(tidyverse)
# Calculate the Probabilites to used in the Vuong Test
calculate_probabilities <- function(model, data){
# Extract the explanatory variables for the ordered component from the data
ordered_var <- data[, colnames(model$x)]
# Get the column names from the inflation component of the model
col_names <- colnames(model$z)
# Clean the column names by removing the 'inflation.' prefix
formatted_col_names <- gsub("inflation.", "", col_names)
# Exclude 'Intercept' from the column names
formatted_col_names <- setdiff(formatted_col_names, "Intercept")
# Extract the intercept from the inflation component of the model
intercept <- unique(model$z[1])
# Construct the 'inflated_data' dataframe using selected columns
# Add a new column 'intercept' with repeated values from the model's intercept
inflated_data <- data[, formatted_col_names, drop = FALSE]
inflated_data$intercept <- rep(intercept,  nrow(inflated_data))
# Reorder columns in 'inflated_data' to place 'intercept' first
inflated_data <- inflated_data[, c("intercept", setdiff(names(inflated_data), "intercept"))]
# Convert the 'intercept' column values to integer
inflated_data$intercept <- unlist(inflated_data$intercept)
inflated_data$intercept <- as.integer(inflated_data$intercept)
# Calculate the product of the 'inflated_data' and model's inflation coefficients
# This is the 'infla' part of the model's probability calculations
inflation_result <- as.matrix(inflated_data) %*% model$coefficients$inflation
# Calculate the product of the 'ordered_var' and model's ordered coefficients
# This is the 'ordered' part of the model's probability calculations
ordered_result <- as.matrix(ordered_var) %*% model$coefficients$ordered
# Prepare cut-point probabilities matrix(i,e thresholds which determines the position of
#the ordered variable)
cutpoint_probs <- matrix(nrow=model$y.categories-1,ncol=1)
# Get number of rows in inflated_data
num_rows <- nrow(inflated_data)
# Prepare probabilities matrix
probabilities <- matrix(nrow=num_rows,ncol=model$y.categories)
cutpoint_probs[1,1] <- model$coefficients$cutpoints[1]
# Calculate cutpoint probabilities
for(j in 2:(model$y.categories-1)){
cutpoint_probs[j,1] <- cutpoint_probs[j-1,1] + exp(model$coefficients$cutpoints[j])
}
# Calculate the last and first categories
probabilities[,model$y.categories] <- (pnorm(inflation_result)) * (1 - pnorm(cutpoint_probs[model$y.categories-1,1] - ordered_result))
probabilities[,1] <- (1 - pnorm(inflation_result)) + (pnorm(inflation_result)) * pnorm(cutpoint_probs[1,1] - ordered_result)
# Calculate intermediate categories
for(j in 2:(model$y.categories-1)){
probabilities[,j] <- (pnorm(inflation_result)) * ((pnorm(cutpoint_probs[j,1] - ordered_result)) - (pnorm(cutpoint_probs[j-1,1] - ordered_result)))
}
# Set column names of the probabilities matrix
colnames(probabilities) <- paste("Pr(Y=", sort(unique(model$y)), ")", sep="")
return(probabilities)
}
vuong_test <- function(trad_ordinal_model,  ZIOP_model, data) {
# Voung test for comparing the Traditional Ordered Probit model and the Zero-Inflated Ordered Probit model.
# trad_ordinal_model: Traditional Ordered Probit model.
# ZIOP_model: Zero-Inflated Ordered Probit model.
# Extracting the length of the data.
len1 <- trad_ordinal_model$n
# Extracting response variables and explanatory variables from the data.
y <- data$recoded_severity  #Manually input this into this function
x <- data[, colnames(ZIOP_model$x)] #
# Initializing a new floating points array for the thresholds of the Traditional Ordered Probit model.
float_threshold <- rep(0, length(unname(trad_ordinal_model$alpha)))
# Grab the coefficients of the model excluding the cut-points in the Traditional Ordered Probit model.
trad_coefs <- unname(trad_ordinal_model$beta)
# Removing names from the threshold arrays
float_threshold <- unname(trad_ordinal_model$alpha)
# Instantiate a model matrix for the explanatory variables.
x_variable <- matrix(nrow = len1, ncol = ncol(x))
# Populate the model matrix using element-wise multiplication between
# explanatory variables in the zero-inflated model and estimates from the Traditional Ordered Probit model.
for (j in 1:ncol(x)) {
x_variable[, j] <- trad_coefs[j] * x[, j]
}
# Calculate the row sums of the model matrix.
x_variable_sum <- rowSums(x_variable)
# Extracting predicted probabilities from the zero-inflated model
# This a function for calculating probabilities(Written above this one)
predict_prob <- calculate_probabilities(model = ZIOP_model, data = data)
# Converting response variable to factor and extracting unique categories.
y_factor <- as.factor(y)
unique_categories <- unique(y_factor)
num_categories <- length(unique_categories)
sorted_categories <- sort(unique_categories)
# Creating a matrix to store indicator variables for each category.
# v: Matrix of indicator variables to represent each category of the response variable 'y'.
# Each column of 'v' corresponds to a distinct category, and each row represents an observation.
# If an observation belongs to a certain category, the corresponding element in that column is set to TRUE (1); otherwise, it is set to FALSE (0).
v <- matrix(0, nrow = len1, ncol = num_categories)
for (j in 1:num_categories) {
v[, j] <- y == sorted_categories[j]
}
# m: A numeric vector initialized with zeros to store the calculated probabilities for each observation.
m <- rep(0, len1)
# probs: A matrix to store the probabilities of each observation belonging to each category.
# The first column (probs[, 1]) represents the probabilities of being in the first category,
# and the last column (probs[, num_categories]) represents the probabilities of being in the last category.
probs <- matrix(0, nrow = len1, ncol = num_categories)
# Calculating the probability of being in the first category.
probs[, 1] <- pnorm(float_threshold[[1]] - x_variable_sum) / predict_prob[, 1]
# Calculating the probability of being in the last category.
probs[, num_categories] <- (1 - pnorm(float_threshold[num_categories - 1] - x_variable_sum)) / predict_prob[, num_categories]
# Calculating the probabilities of being in the intermediate categories.
for (i in 2:(num_categories - 1)) {
probs[, i] <- (pnorm(float_threshold[i] - x_variable_sum) - pnorm(float_threshold[i - 1] - x_variable_sum)) / predict_prob[, i]
}
# Calculating the weighted probabilities for each observation and category.
m <- matrix(0, nrow = len1, ncol = num_categories)
for (k in 1:len1) {
for (j in 1:num_categories) {
m[k, j] <- v[k, j] * probs[k, j]
}
}
# Removing no zero values
m[m[,1] == 0, 1] <- apply(m[m[,1] == 0,], 1, function(x) x[x!=0][1])
# Now keep only the first column
m2 <- m[ , 1, drop = FALSE]
# Calculating the log-likelihood for each observation and category.
mlog <- log(m2)
diffmsq <- (mlog - mean(mlog)) **2
sumdms <- sum(diffmsq)
# Calculating the Vuong test statistic.
numerator = sqrt(len1) * ((1/len1) * sum(mlog))
denominator =  sqrt((1 / len1) * sumdms)
vuong_test <- numerator / denominator
#Returning the Vuong test
return(vuong_test)
}
marginal_effect_ordered <- function(ZIOP_MODEL, data, rho) {
response_variable <- length(unique(ZIOP_MODEL$y))
# Extract the ordered Probit coefficients from the ZIOP model
ordered_estimates <- unname(ZIOP_MODEL$coefficients$ordered)
# Extract the inflation coefficients from the ZIOP model, excluding the intercept
infl_estimates <- unname(ZIOP_MODEL$coefficients$inflation[-1])
intercept_term <- unname(ZIOP_MODEL$coefficients$inflation[1])
# Extracting coefficient common to both part of the model
#unique_val <- c(Gamma, Beta)
# xi represents the variables used in the ordered component of the ZIOP model
x_variables <- as.matrix(data[, colnames(ZIOP_MODEL$x)])
col_names_x <- colnames(ZIOP_MODEL$x)
# Get column names from the ZIOP model's inflation variables
col_names_z <- colnames(ZIOP_MODEL$z)
# Clean the column names by removing the 'inflation.' prefix
col_names_z <- gsub("inflation.", "", col_names_z)
# Remove the first element from the column names vector, which is the intercept term
col_names_z <- col_names_z[-1]
# Extract inflation variables from the data using the cleaned column names and convert to a matrix
z_variables <- as.matrix(data[, col_names_z])
# Extracting the levels of severity in the in the model
J_levels_ordered <- unique(ZIOP_MODEL$y)
# Create the formula for the model ordered section of the model
form_x  <- paste("~ 1", paste("+", col_names_x, collapse = " "), collapse = " ")
# Create the formula for the Binary Probit section of the model
form_z  <- paste("~ 1", paste("+", col_names_z, collapse = " "), collapse = " ")
# Generate the design matrix for the model. Excluding the intercept.
x_lin <- model.matrix(as.formula(form_x), data = data)[, -1]
z_lin <- model.matrix(as.formula(form_z), data = data)[, -1]
# since Marginal effects could be  calculated at the mean of the independent variables(joint mean of the covariates)
# The mean of independent variables for both the Binary and Ordered probit are calculated.
# The Author chose to calculate the Marginal effect at the join mean of the covariates below.
x_mean <- as.matrix(colMeans(x_lin))
Y_mean <- as.matrix(colMeans(z_lin))
# Calculate XB and zY by multiplying the mean and model estimates
xb <- t(x_mean) %*% ordered_estimates
zY <- t(Y_mean) %*% infl_estimates
# assign  X* and Y* to a variable. They include coefficients associated not only with the variables included
# in either Binary or Ordered probit but also the common variables that appear in both equations.
# Extracting coefficients
ordered_coefs <- ZIOP_MODEL$coefficients$ordered
inflation_coefs <- ZIOP_MODEL$coefficients$inflation[-1]
# Finding unique and common variable names
common_vars_names <- intersect(names(ordered_coefs), names(inflation_coefs))
unique_ordered_vars_names <- setdiff(names(ordered_coefs), common_vars_names)
unique_inflation_vars_names <- setdiff(names(inflation_coefs), common_vars_names)
# Populate x_asteric and Y_asteric lists based on the unique and common variables
x_asteric <- list()
Y_asteric <- list()
# Looping through the variables to find unique or common variables for x* AND  Y*
if (length(unique_ordered_vars_names) > 0 || length(unique_inflation_vars_names) > 0) {
# For ordered_coefs
x_asteric[common_vars_names] <- ordered_coefs[common_vars_names]
x_asteric[unique_ordered_vars_names] <- ordered_coefs[unique_ordered_vars_names]
# For inflation_coefs
Y_asteric[common_vars_names] <- inflation_coefs[common_vars_names]
Y_asteric[unique_inflation_vars_names] <- inflation_coefs[unique_inflation_vars_names]
} else {
x_asteric[common_vars_names] <- ordered_coefs[common_vars_names]
Y_asteric[common_vars_names] <- inflation_coefs[common_vars_names]
}
# Removing the inflation.name(ie. inflation.age hence making it just age)
names(Y_asteric) <- gsub("inflation.", "", names(Y_asteric))
#Converting list to Matix for allow for multiplication and transposing them
x_asteric_mat <- as.matrix(unlist(x_asteric))
x_asteric_mat <- t(x_asteric_mat)
Y_asteric_mat <- as.matrix(unlist(Y_asteric))
Y_asteric_mat  <- t(Y_asteric_mat)
# Extract the cut-points (threshold parameters) from the ZIOP model
alpha <-  summary(ZIOP_MODEL)$coefficients[grep("^cut", rownames(summary(ZIOP_MODEL)$coefficients)), "Estimate"]
alpha <- c(-10^6, alpha, 10^6)  # Set lower and upper bounds for the cut-points
# Calculating the Marginal effects for the Zero inflated Ordered Probit Model
binary_prob <- (pnorm((alpha[2:(response_variable + 1)] - c(xb) + c(rho * zY)) / sqrt(1 - rho^2)) -
pnorm((alpha[1:response_variable] - c(xb) + c(rho * zY)) / sqrt(1 - rho^2))) * dnorm(c(zY))
ordered_prob <- pnorm((c(zY + rho) * (alpha[1:response_variable] -c(xb))) / sqrt(1 - rho^2)) * dnorm(alpha[1:response_variable] - c(xb)) -
pnorm((c(zY + rho) * (alpha[2:(response_variable + 1)] - c(xb))) / sqrt(1 - rho^2))  * dnorm(alpha[2:(response_variable + 1)] - c(xb))
# Multiply by X* and Y* which represents coefficients associated not only with the variables included
# in either Binary or Ordered probit but also the common variables that appear in both equations
binary_probit_effect <- as.vector(Y_asteric_mat) %*% matrix(data =  binary_prob, nrow = 1)
ordered_probit_effect <- as.vector(x_asteric_mat) %*% matrix(data = ordered_prob, nrow = 1)
# Add the Marginal effect for both term one and term two
overall_marginal_effect <- binary_probit_effect + ordered_probit_effect
# Assign the row names and column to the binary and Ordered probit section of the returned data.,
# Passing variables to a data frame.
binary_probit_effect <- as.data.frame(binary_probit_effect)
ordered_probit_effect<- as.data.frame(ordered_probit_effect)
overall_marginal_effect <- as.data.frame(overall_marginal_effect)
row.names(binary_probit_effect) <- col_names_z
row.names(ordered_probit_effect) <- col_names_x
# renaming the columns for the Ordered probit section.
colnames(ordered_probit_effect)[colnames(ordered_probit_effect) %in% c("V1", "V2", "V3")] <- c("Minor Injury",
"Serious Injury", "Fatal Injury")
# Return various Marginal effect component
return(list(Binary_Probit = binary_probit_effect, Ordered_Probit = ordered_probit_effect,
Overall_effect = overall_marginal_effect))
}
# Navigate to the 'Results' folder within the current working directory
setwd("Results_Darkness")
write.csv(ziop_model, 'Estimates_ZIOP_darkness.csv', row.names = FALSE)
# Saving the results of the Ordered Probit model to a csv file.
Op_final_results <-  final_op_darkness$coefficients
Op_final_results <- as.data.frame(Op_final_results)
write.csv(Op_final_results, 'Estimates_OP_daylight.csv', row.names = FALSE)
write.csv(Op_final_results, 'Estimates_OP_darkness.csv', row.names = FALSE)
###################################################################################################################################################
# Calculate AIC BIC and Log likelihood for the Ordered Probit model and them to csv
compute_AIC_BIC_LL <- function(model, file_suffix) {
aic <- AIC(model)
print(paste("AIC:", aic))
bic <- BIC(model)
print(paste("BIC:", bic))
logLik_value <- logLik(model)
print(paste("Log-Likelihood:", logLik_value))
# Create data frames for AIC, BIC, and log-likelihood values
aic_df <- data.frame(AIC = aic)
bic_df <- data.frame(BIC = bic)
log_likelihood_df <- data.frame(LogLikelihood = logLik_value)
# Save the data frames to separate CSV files with the specified file_suffix
write.csv(aic_df, file = paste0("AIC_", file_suffix, ".csv"), row.names = FALSE)
write.csv(bic_df, file = paste0("BIC_", file_suffix, ".csv"), row.names = FALSE)
write.csv(log_likelihood_df, file = paste0("LogLikelihood_", file_suffix, ".csv"), row.names = FALSE)
}
# Calculate AIC, BIC and Log Likelihood for the zero inflated Ordered Probit Model(ZIOP Model)
calculate_AIC_BIC_LL_ZIOP <- function(model, n ){
# Run the function for calculating AIC and BIC first before running this function
estimates <- calculate_AIC_BIC(model = model , n = n)  # Custom code that calculates AIC and BIC for the ZIOP MODEL
ZIOP_AIC <- estimates$AIC
print(paste("AIC:",  ZIOP_AIC))
ZIOP_BIC <- estimates$BIC
ZIOP_BIC
print(paste("BIC:",  ZIOP_BIC))
ZIOP_Log_likelihood <- model$ll
ZIOP_Log_likelihood
print(paste("Likelihood:",  ZIOP_Log_likelihood))
# Create data frames for AIC, BIC, and log-likelihood values
aic_df_ziop <- data.frame(AIC = ZIOP_AIC)
bic_df_ziop <- data.frame(BIC = ZIOP_BIC)
log_likelihood_df_ziop <- data.frame(LogLikelihood = ZIOP_Log_likelihood)
# Save the data frames to separate CSV files with the specified file_suffix
write.csv(aic_df_ziop, file = paste0("AIC_", "Ziop_model_darkness", ".csv"), row.names = FALSE)
write.csv(bic_df_ziop, file = paste0("BIC_", "Ziop_model_darkness", ".csv"), row.names = FALSE)
write.csv(log_likelihood_df_ziop, file = paste0("LogLikelihood_darkness_", "Ziop_model", ".csv"), row.names = FALSE)
}
# Calculate AIC, BIC and Log Likelihood for the zero inflated Ordered Probit Model(ZIOP Model)
calculate_AIC_BIC_LL_ZIOP <- function(model, n ){
# Run the function for calculating AIC and BIC first before running this function
# estimates <- calls the calculate_AIC_BIC function
estimates <- calculate_AIC_BIC(model = model , n = n)  # Custom code that calculates AIC and BIC for the ZIOP MODEL
ZIOP_AIC <- estimates$AIC
print(paste("AIC:",  ZIOP_AIC))
ZIOP_BIC <- estimates$BIC
ZIOP_BIC
print(paste("BIC:",  ZIOP_BIC))
ZIOP_Log_likelihood <- model$ll
ZIOP_Log_likelihood
print(paste("Likelihood:",  ZIOP_Log_likelihood))
# Create data frames for AIC, BIC, and log-likelihood values
aic_df_ziop <- data.frame(AIC = ZIOP_AIC)
bic_df_ziop <- data.frame(BIC = ZIOP_BIC)
log_likelihood_df_ziop <- data.frame(LogLikelihood = ZIOP_Log_likelihood)
# Save the data frames to separate CSV files with the specified file_suffix
write.csv(aic_df_ziop, file = paste0("AIC_", "Ziop_model_darkness", ".csv"), row.names = FALSE)
write.csv(bic_df_ziop, file = paste0("BIC_", "Ziop_model_darkness", ".csv"), row.names = FALSE)
write.csv(log_likelihood_df_ziop, file = paste0("LogLikelihood_darkness_", "Ziop_model", ".csv"), row.names = FALSE)
}
# Return values for the ordered Probit model for comparison
compute_AIC_BIC_LL(final_op_darkness, "Op_model_darkness")
# Return values for Zero inflated Ordered Probit model for Comparison
calculate_AIC_BIC_LL_ZIOP(ziop_two_darkness, 1094)
# Function to calculate AIC and BIC for a custom zero-inflated model
calculate_AIC_BIC <- function(model, n) {
# Model: Pass Custom Zero-inflated model component
# n: Total number of observations in the model
nll <- model$ll  #  log-likelihood
num_parameters <- sum(sapply(model$coefficients, length))  # Number of estimated parameters
AIC <- -2 * nll + 2 * num_parameters
BIC <- -2 * nll + log(n) * num_parameters
return(list(AIC = AIC, BIC = BIC))
}
# Return values for Zero inflated Ordered Probit model for Comparison
calculate_AIC_BIC_LL_ZIOP(ziop_two_darkness, 1094)
# Return values for the ordered Probit model for comparison
compute_AIC_BIC_LL(final_op_darkness, "Op_model_darkness")
# Return values for Zero inflated Ordered Probit model for Comparison
calculate_AIC_BIC_LL_ZIOP(ziop_two_darkness, 1094)
####################################################################################################################################################
# Calculating the Vuong test and Marginal effect for the Zero inflated Ordered Probit Model.
# The Vuong test score between the Ordered Probit model and the Zero Inflated Ordered Probit Model.
# Storing the results in a csv file
voung_result <- vuong_test(final_op_darkness, ziop_two_darkness, prep_data) # A custom code that calculates the Vuong test.
voung_result_df <- data.frame(voung_result)
write.csv(voung_result_df, 'vuong_test_result_daylight.csv', row.names = FALSE)
voung_result
# Marginal effect for the Zero inflated Ordered Probit Model
ziop_marginal_result <- marginal_effect_ordered(ziop_two_darkness, prep_data, rho = 0) # A custom code for Calculating Marginal effect.
ziop_marginal_result_df <- data.frame(ziop_marginal_result$Ordered_Probit)
write.csv(ziop_marginal_result_df, 'ziop_marginal_result_daylight.csv', row.names = FALSE)
ziop_marginal_result_df
summary(ziop_two_darkness)
summary(ziop_two_darkness)
# Return values for the ordered Probit model for comparison
compute_AIC_BIC_LL(final_op_darkness, "Op_model_darkness")
# Return values for Zero inflated Ordered Probit model for Comparison
calculate_AIC_BIC_LL_ZIOP(ziop_two_darkness, 1094)
ziop_marginal_result_df
voung_result
rm(list = ls())
